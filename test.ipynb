{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 필요 모듈 설치"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n","!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:35:57.680397Z","iopub.status.busy":"2021-12-04T14:35:57.680176Z","iopub.status.idle":"2021-12-04T14:36:03.730162Z","shell.execute_reply":"2021-12-04T14:36:03.729283Z","shell.execute_reply.started":"2021-12-04T14:35:57.680372Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","\n","import segmentation_models_pytorch as smp\n","import albumentations as albu"]},{"cell_type":"markdown","metadata":{},"source":["## 경로 설정"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.572315Z","iopub.status.busy":"2021-12-04T14:36:10.572121Z","iopub.status.idle":"2021-12-04T14:36:10.575284Z","shell.execute_reply":"2021-12-04T14:36:10.574651Z","shell.execute_reply.started":"2021-12-04T14:36:10.572292Z"},"trusted":true},"outputs":[],"source":["segmentation_path = '../input/lv2-dataset/SIA_pytorch/segmentation_models'\n","\n","best_model = torch.load('../input/lv2-dataset/best_model.pth')\n","\n","x_valid_dir = '../input/lv2-dataset/LV2_validation_set/images'\n","y_valid_dir = '../input/lv2-dataset/LV2_validation_set/labels'"]},{"cell_type":"markdown","metadata":{},"source":["## 데이터로더 정의"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.577066Z","iopub.status.busy":"2021-12-04T14:36:10.576686Z","iopub.status.idle":"2021-12-04T14:36:10.590653Z","shell.execute_reply":"2021-12-04T14:36:10.589984Z","shell.execute_reply.started":"2021-12-04T14:36:10.577033Z"},"trusted":true},"outputs":[],"source":["class Dataset(BaseDataset):\n","    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n","    \n","    Args:\n","        images_dir (str): path to images folder\n","        masks_dir (str): path to segmentation masks folder\n","        class_values (list): values of classes to extract from segmentation mask\n","        augmentation (albumentations.Compose): data transfromation pipeline \n","            (e.g. flip, scale, etc.)\n","        preprocessing (albumentations.Compose): data preprocessing \n","            (e.g. noralization, shape manipulation, etc.)\n","    \n","    \"\"\"\n","    \n","    CLASSES = ['building', 'road']\n","    \n","    def __init__(\n","            self, \n","            images_dir, \n","            masks_dir, \n","            classes=None, \n","            augmentation=None, \n","            preprocessing=None,\n","    ):\n","        self.ids = os.listdir(images_dir)\n","        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n","        \n","        # convert str names to class values on masks\n","        self.class_values = [200, 255]\n","        \n","        self.augmentation = augmentation\n","        self.preprocessing = preprocessing\n","    \n","    def __getitem__(self, i):\n","        # read data\n","        image = cv2.imread(self.images_fps[i])\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.masks_fps[i], 0)\n","        \n","        # extract certain classes from mask (e.g. cars)\n","        masks = [(mask == v) for v in self.class_values]\n","        mask = np.stack(masks, axis=-1).astype('float')\n","        \n","        # apply augmentations\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","        \n","        # apply preprocessing\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']  \n","\n","        return image, mask\n","        \n","    def __len__(self):\n","        return len(self.ids)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.592243Z","iopub.status.busy":"2021-12-04T14:36:10.591820Z","iopub.status.idle":"2021-12-04T14:36:10.603192Z","shell.execute_reply":"2021-12-04T14:36:10.602462Z","shell.execute_reply.started":"2021-12-04T14:36:10.592206Z"},"trusted":true},"outputs":[],"source":["def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')\n","\n","\n","def get_preprocessing(preprocessing_fn):\n","    \"\"\"Construct preprocessing transform\n","    \n","    Args:\n","        preprocessing_fn (callbale): data normalization function \n","            (can be specific for each pretrained neural network)\n","    Return:\n","        transform: albumentations.Compose\n","    \n","    \"\"\"\n","    \n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.604716Z","iopub.status.busy":"2021-12-04T14:36:10.604474Z","iopub.status.idle":"2021-12-04T14:36:10.612509Z","shell.execute_reply":"2021-12-04T14:36:10.611802Z","shell.execute_reply.started":"2021-12-04T14:36:10.604683Z"},"trusted":true},"outputs":[],"source":["ENCODER = 'efficientnet-b7'\n","ENCODER_WEIGHTS = 'imagenet'\n","DEVICE = 'cuda'\n","CLASSES = ['building', 'road']\n","\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.632499Z","iopub.status.busy":"2021-12-04T14:36:10.632187Z","iopub.status.idle":"2021-12-04T14:36:10.652752Z","shell.execute_reply":"2021-12-04T14:36:10.652170Z","shell.execute_reply.started":"2021-12-04T14:36:10.632465Z"},"trusted":true},"outputs":[],"source":["valid_dataset = Dataset(\n","    x_valid_dir, \n","    y_valid_dir, \n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=CLASSES,\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.655425Z","iopub.status.busy":"2021-12-04T14:36:10.655242Z","iopub.status.idle":"2021-12-04T14:36:10.659348Z","shell.execute_reply":"2021-12-04T14:36:10.658726Z","shell.execute_reply.started":"2021-12-04T14:36:10.655404Z"},"trusted":true},"outputs":[],"source":["loss = smp.utils.losses.DiceLoss()\n","metrics = [\n","    smp.utils.metrics.IoU(threshold=0.5),\n","]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:36:10.661251Z","iopub.status.busy":"2021-12-04T14:36:10.660785Z","iopub.status.idle":"2021-12-04T14:36:10.685468Z","shell.execute_reply":"2021-12-04T14:36:10.684877Z","shell.execute_reply.started":"2021-12-04T14:36:10.661217Z"},"trusted":true},"outputs":[],"source":["valid_epoch = smp.utils.train.ValidEpoch(\n","    model=best_model, \n","    loss=loss, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n","\n","valid_dataset_vis = Dataset(\n","    x_valid_dir, y_valid_dir, \n","    classes=CLASSES,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 모델 검증"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["start = torch.cuda.Event(enable_timing=True) \n","end = torch.cuda.Event(enable_timing=True)\n","for i in range(2):\n","    start.record()\n","    valid_logs = valid_epoch.run(valid_loader)\n","    end.record()\n","    torch.cuda.synchronize()\n","\n","    print(f'FPS : {(start.elapsed_time(end)/len(valid_loader))/1000}')"]},{"cell_type":"markdown","metadata":{},"source":["## 이미지 시각화"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:38:28.335984Z","iopub.status.busy":"2021-12-04T14:38:28.335150Z","iopub.status.idle":"2021-12-04T14:38:28.341087Z","shell.execute_reply":"2021-12-04T14:38:28.340295Z","shell.execute_reply.started":"2021-12-04T14:38:28.335945Z"},"trusted":true},"outputs":[],"source":["def combine_masks(masks):\n","  # masks should be size (channels, w, h)\n","  output_mask = np.zeros(masks[0].shape, dtype=np.uint8)\n","\n","  for i, mask in enumerate(masks):\n","    output_mask[mask==1] = i + 1\n","\n","  return output_mask"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:38:28.343272Z","iopub.status.busy":"2021-12-04T14:38:28.342716Z","iopub.status.idle":"2021-12-04T14:38:28.354290Z","shell.execute_reply":"2021-12-04T14:38:28.353564Z","shell.execute_reply.started":"2021-12-04T14:38:28.343234Z"},"trusted":true},"outputs":[],"source":["def visualize(**images):\n","    \"\"\"PLot images in one row.\"\"\"\n","    n = len(images)\n","    plt.figure(figsize=(16, 5))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        plt.imshow(image)\n","    plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T14:38:28.356534Z","iopub.status.busy":"2021-12-04T14:38:28.355914Z","iopub.status.idle":"2021-12-04T14:38:36.495953Z","shell.execute_reply":"2021-12-04T14:38:36.495304Z","shell.execute_reply.started":"2021-12-04T14:38:28.356495Z"},"trusted":true},"outputs":[],"source":["for i in range(10):\n","    n = np.random.choice(len(valid_dataset))\n","    \n","    image_vis = valid_dataset_vis[n][0].astype('uint8')\n","    image, gt_mask = valid_dataset[n]\n","    \n","    gt_mask = gt_mask.squeeze()\n","    \n","    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n","    pr_mask = best_model.predict(x_tensor)\n","    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n","        \n","    visualize(\n","        image=image_vis, \n","        gt_mask=combine_masks(gt_mask),\n","        pr_mask=combine_masks(pr_mask),\n","    )"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.14 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.14"},"vscode":{"interpreter":{"hash":"a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"}}},"nbformat":4,"nbformat_minor":4}
